[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The_Impact_of_COVID_On_Education",
    "section": "",
    "text": "1 Introduction\nThe COVID-19 pandemic disrupted nearly every aspect of society across the world, including educational performance. As students who experienced these challenges, we wanted to better understand how the pandemic affected student performance globally. In this project, we will analyze data from the Programme for International Student Assessment (PISA) in 2018 and 2022 (before and after the pandemic) to explore changes in student performance. Our goal is to first measure the impact of the pandemic on education and identify contributing or confounding factors that may explain differences across countries. We also hope to examine how various countries‚Äô responses to the pandemic in terms of education may have influenced their results.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2¬† Data",
    "section": "",
    "text": "2.1 Description\nOur primary data source is the PISA dataset published by the Organization for Economic Cooperation and Development (OECD). The OECD is an international organization that develops standards that allow for more evidence based policies across the globe, including educational standards. Given its established reputation and collaboration with official governmental educational institutions, we believe this is a credible source.\nDisregarding a delay due to the pandemic, the PISA assessment is conducted once every three years and aims to evaluate the knowledge and skills of 15-year-old students in reading, mathematics, and science. By simulating real-world situations, the test aims to determine whether students can apply their knowledge rather than merely memorizing. The data is collected through a standardized testing approach with consistent administration environments in each country participating in the data collection. This ensures that it can be compared across countries.\nFor this project‚Äôs analysis, we will be using the PISA data from 2018 (pre-pandemic) and 2022 (post-pandemic) which are available on the published PISA reports on the OECD official website. The datasets are provided in XLSX formats with each file containing each country, their corresponding PISA scores, and country statistics (like GDP and education spending).\nIn the report, there are many different tables and datasets that are available for our use. We want to use the table where we have the average scores for each country, ranked from highest to lowest. PISA 2018 was last updated in December 2019, but there is no definite update date for PISA 2022, which we can assume to be sometime around the end of 2022.\nOne issue with the data is that though the OECD strives to maintain consistency across years, the pandemic caused various disruptions which, though documented clearly, could introduce noise into some cross country comparisons. However, this project is focusing on change from pre- to post-pandemic so cross country comparisons will be seldom made.\nSomething we want to be cognizant of is the fact that these scores might be fluctuating over the years due to other factors independent of the pandemic. To take care of this, we are planning to look into other data sources.\nData:\nhttps://www.oecd.org/en/publications/pisa-2018-results-volume-i_5f07c754-en.html\nhttps://www.oecd.org/en/data/datasets/pisa-2022-database.html\nBesides overarching global comparisons, we wanted to dive deeper into a few countries and analyze what actions they took regarding education during the pandemic and how that might explain their difference in PISA scores.\nFinland:\nFor Finland, we found various datasets in research papers looking for the effect of the pandemic on education in Finland.\nThe first paper we found was written by Harvard‚Äôs Department of Education and published in 2023. It provides several analyses of student/teacher engagement, burnout, and general attitudes throughout the pandemic.\nData:\nhttps://link.springer.com/chapter/10.1007/978-3-031-42671-1_4\nhttps://link.springer.com/article/10.1007/s10902-022-00518-1/tables/3\nOur second source is a report from the OECD which we‚Äôve already explained is a highly credible source, and was published in December of 2020. This source puts together several data sources that discuss the actions Finland took to switch to distance learning and the impact of them.\nData:\nhttps://www.oecd.org/content/dam/oecd/en/about/projects/edu/education-policy-outlook/covid-snapshot-Finland.pdf\nUnited States:\nIn addition to Finland, we decided to look into data from the US. Google has health data for COVID-19 that is credible and verified. It is one of the largest collections of COVID data available to use, compiled from various sources. Through this dataset, we can examine how the different factors, such as socioeconomic factors, can affect how the virus affected various groups of people, giving us a better understanding of the effects of the pandemic.\nData: https://health.google.com/covid-19/open-data/raw-data\nThe 2021-2022 School Learning Modalities dataset contains information about the learning modality for primary and secondary schools. The data was aggregated from multiple data sources to determine the likely learning modality of the school district. The data was provided by the CDC.\nData: https://healthdata.gov/National/School-Learning-Modalities-2021-2022/aitj-yx37/about_data\nThe final dataset is from the National Center for Education Statistics and it is data regarding the U.S. education at the time of COVID. There‚Äôs a variety of data regarding the activities of people during this time, such as the number of adults with children who had their students attending summer programs or working with private tutors. We hope to use this data to gain more data about the ways students and parents coped with the changes in education during this turbulent time.\nData: https://nces.ed.gov/surveys/annualreports/topical-studies/covid/",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#required-packages-and-data-loading",
    "href": "data.html#required-packages-and-data-loading",
    "title": "2¬† Data",
    "section": "2.2 Required Packages and Data Loading",
    "text": "2.2 Required Packages and Data Loading\n\n\nCode\n# install.packages(c(\"dplyr\",\"tidyr\",\"ggplot2\",\"ggalluvial\",\"forcats\",'ggtext'))\nlibrary(dplyr) \n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(tidyr)\nlibrary(tidyverse)\n\n\nWarning: package 'ggplot2' was built under R version 4.5.2\n\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî forcats   1.0.1     ‚úî readr     2.1.5\n‚úî ggplot2   4.0.1     ‚úî stringr   1.5.2\n‚úî lubridate 1.9.4     ‚úî tibble    3.3.0\n‚úî purrr     1.1.0     \n\n\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(ggplot2)\nlibrary(ggalluvial)\nlibrary(forcats)\nlibrary(ggridges)\n#library(Lock5withR)\n\n\n\n\nCode\n# Loading in the PISA datasets:\npisa2009 &lt;- read.csv('data/2009_PISA.csv')\npisa2012 &lt;- read.csv('data/2012_PISA.csv')\npisa2015 &lt;- read.csv('data/2015_PISA.csv')\npisa2018 &lt;- read.csv('data/2018_PISA.csv')\npisa2022 &lt;- read.csv('data/2022_PISA.csv')",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2¬† Data",
    "section": "2.3 Missing value analysis",
    "text": "2.3 Missing value analysis\n** dont have it for a couple of years ‚Äì&gt; alluvial\n\n\nCode\n# List of country participation across years:\nparticipation_list &lt;- list(\n  '2009' = pisa2009$X,\n  '2012' = pisa2012$Country,\n  '2015' = pisa2015$X,\n  '2018' = pisa2018$Country,\n  '2022' = pisa2022$Country\n)\n\n# row and column values\nall_countries &lt;- unique(unlist(participation_list))\nyears &lt;- names(participation_list)\n\n# dataframe used for alluvial\nparticipation_long &lt;- participation_list |&gt;\n  enframe(name = \"year\", value = \"country\") |&gt;\n  unnest(country) |&gt;\n  mutate(status = \"participated\")\n\nparticipation_df &lt;- participation_long |&gt;\n  pivot_wider(\n    names_from = year,\n    values_from = status,\n    values_fn = ~ first(.x)\n    # values_fill = \"not participated\"\n  ) \n\nparticipation_df$`2009` &lt;- replace_na(participation_df$`2009`, \"not participated\")\nparticipation_df$`2012` &lt;- replace_na(participation_df$`2012`, \"not participated\")\nparticipation_df$`2015` &lt;- replace_na(participation_df$`2015`, \"not participated\")\nparticipation_df$`2018` &lt;- replace_na(participation_df$`2018`, \"not participated\")\nparticipation_df$`2022` &lt;- replace_na(participation_df$`2022`, \"not participated\")\n\nparticipation_df$total_participated &lt;- as.factor(rowSums(participation_df[, -1] == \"participated\", na.rm = TRUE))\n\n\n\n\nCode\nggplot(data = participation_df,\n       aes(axis1 = `2009`, axis2 = `2012`, axis3 = `2015`, axis4 = `2018`, axis5=`2022`)) +\n  geom_alluvium(aes(fill = total_participated), alpha = 0.7) +\n  geom_stratum(alpha = 0.9) +\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum)), size = 3) +\n  scale_x_discrete(limits = c(\"2009\", \"2012\", \"2015\", \"2018\", \"2022\"), \n                   expand = c(0.15, 0.05)) +\n  theme_minimal() +\n  labs(title = \"Country Participation Over Time\",\n       y = \"Number of Countries\") +\n  theme(legend.position = \"right\",\n        plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n        axis.title.x = element_blank())\n\n\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "3¬† Results",
    "section": "",
    "text": "3.0.0.1 Required Packages and Data Loading\n\n\nCode\n# install.packages(c(\"dplyr\",\"tidyr\",\"ggplot2\",\"ggalluvial\",\"forcats\",'ggtext'))\nlibrary(dplyr) \n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(tidyr)\nlibrary(tidyverse)\n\n\nWarning: package 'ggplot2' was built under R version 4.5.2\n\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî forcats   1.0.1     ‚úî readr     2.1.5\n‚úî ggplot2   4.0.1     ‚úî stringr   1.5.2\n‚úî lubridate 1.9.4     ‚úî tibble    3.3.0\n‚úî purrr     1.1.0     \n\n\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(ggplot2)\nlibrary(ggalluvial)\nlibrary(forcats)\nlibrary(ggridges)\nlibrary(sf)\n\n\nLinking to GEOS 3.13.0, GDAL 3.8.5, PROJ 9.5.1; sf_use_s2() is TRUE\n\n\nCode\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\n\n\n\nAttaching package: 'rnaturalearthdata'\n\nThe following object is masked from 'package:rnaturalearth':\n\n    countries110\n\n\nCode\nlibrary(patchwork)\nlibrary(ggrepel)\nlibrary(vcd)\n\n\nLoading required package: grid\n\n\nCode\nlibrary(scales) # Required for label_number()\n\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n\nCode\n#library(Lock5withR)\n\n\n\n\nCode\n# Loading in the PISA datasets:\npisa2009 &lt;- read.csv('data/2009_PISA.csv')\npisa2012 &lt;- read.csv('data/2012_PISA.csv')\npisa2015 &lt;- read.csv('data/2015_PISA.csv')\npisa2018 &lt;- read.csv('data/2018_PISA.csv')\npisa2022 &lt;- read.csv('data/2022_PISA.csv')\n\nparticipation_list &lt;- list(\n  '2009' = pisa2009$X,\n  '2012' = pisa2012$Country,\n  '2015' = pisa2015$X,\n  '2018' = pisa2018$Country,\n  '2022' = pisa2022$Country\n)\nall_countries &lt;- unique(unlist(participation_list))\n\n\n\n\nCode\n# Reading Scores Full Table\nall_reading_scores &lt;- data.frame(country = all_countries) |&gt;\n  left_join(select(pisa2009, X, On.the.overall.reading.scale), by=c(\"country\" = \"X\")) |&gt;\n  left_join(select(pisa2012, Country, Mean.score.in.PISA.2012...Reading), by=c(\"country\" = \"Country\")) |&gt;\n  left_join(select(pisa2015, X, Mean.score.in.PISA.2015...Reading), by=c(\"country\" = \"X\")) |&gt;\n  left_join(select(pisa2018, Country, Reading.Mean), by=c(\"country\" = \"Country\")) |&gt;\n  left_join(select(pisa2022, Country, Reading.Mean), by=c(\"country\" = \"Country\")) |&gt;\n  rename(`2009`=On.the.overall.reading.scale, `2012`=Mean.score.in.PISA.2012...Reading, `2015`=Mean.score.in.PISA.2015...Reading, `2018`=Reading.Mean.x, `2022`=Reading.Mean.y) |&gt;\n  mutate(across(c(`2009`, `2012`, `2015`, `2018`, `2022`), as.numeric))\n\n\nWarning: There were 2 warnings in `mutate()`.\nThe first warning was:\n‚Ñπ In argument: `across(c(`2009`, `2012`, `2015`, `2018`, `2022`), as.numeric)`.\nCaused by warning:\n! NAs introduced by coercion\n‚Ñπ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n\nCode\nall_reading_scores_long &lt;- all_reading_scores |&gt;\n  pivot_longer(!country, names_to=\"year\", values_to=\"score\") |&gt;\n  mutate(across(c(year), as.numeric))\n\n# Math Scores Full Table\nall_math_scores &lt;- data.frame(country = all_countries) |&gt;\n  left_join(select(pisa2009, X, On.the.mathematics.scale), by=c(\"country\" = \"X\")) |&gt;\n  left_join(select(pisa2012, Country, Mean.score.in.PISA.2012...Mathematics), by=c(\"country\" = \"Country\")) |&gt;\n  left_join(select(pisa2015, X, Mean.score.in.PISA.2015...Mathematics), by=c(\"country\" = \"X\")) |&gt;\n  left_join(select(pisa2018, Country, Mathematics.Mean), by=c(\"country\" = \"Country\")) |&gt;\n  left_join(select(pisa2022, Country, Mathematics.Mean), by=c(\"country\" = \"Country\")) |&gt;\n  rename(`2009`=On.the.mathematics.scale, `2012`=Mean.score.in.PISA.2012...Mathematics, `2015`=Mean.score.in.PISA.2015...Mathematics, `2018`=Mathematics.Mean.x, `2022`=Mathematics.Mean.y) |&gt;\n  mutate(across(c(`2009`, `2012`, `2015`, `2018`, `2022`), as.numeric))\n  \nall_math_scores_long &lt;- all_math_scores |&gt;\n  pivot_longer(!country, names_to=\"year\", values_to=\"score\") |&gt;\n  mutate(across(c(year), as.numeric))\n\n# Science Scores Full Table\nall_science_scores &lt;- data.frame(country = all_countries) |&gt;\n  left_join(select(pisa2009, X, On.the.science.scale), by=c(\"country\" = \"X\")) |&gt;\n  left_join(select(pisa2012, Country, Mean.score.in.PISA.2012...Science), by=c(\"country\" = \"Country\")) |&gt;\n  left_join(select(pisa2015, X, Mean.score.in.PISA.2015...Science), by=c(\"country\" = \"X\")) |&gt;\n  left_join(select(pisa2018, Country, Science.Mean), by=c(\"country\" = \"Country\")) |&gt;\n  left_join(select(pisa2022, Country, Science.Mean), by=c(\"country\" = \"Country\")) |&gt;\n  rename(`2009`=On.the.science.scale, `2012`=Mean.score.in.PISA.2012...Science, `2015`=Mean.score.in.PISA.2015...Science, `2018`=Science.Mean.x, `2022`=Science.Mean.y) |&gt;\n  mutate(across(c(`2009`, `2012`, `2015`, `2018`, `2022`), as.numeric))\n  \nall_science_scores_long &lt;- all_science_scores |&gt;\n  pivot_longer(!country, names_to=\"year\", values_to=\"score\") |&gt;\n  mutate(across(c(year), as.numeric))\n\n# Combining all scores\nall_scores_long &lt;- bind_rows(\n  mutate(all_reading_scores_long, subject = \"reading\"),\n  mutate(all_math_scores_long, subject = \"math\"),\n  mutate(all_science_scores_long, subject = \"science\")\n)\n\n\n\n\n3.0.1 global trends\n\nwe‚Äôve already introduced PISA\nso let‚Äôs look at the ridge plot\nwe say that the data is being more bimodal over time\nwe dont know what is exactly changing; we can say data from higher peak is going to lower peak but we are still unsure af\n\n\n\nCode\nggplot(all_scores_long, aes(x = score, y = as.factor(year))) +\n  geom_density_ridges(fill = \"blue\") +\n  ggtitle(\"Overall PISA Scores Over Time\") +\n  ylab(\"year\")\n\n\nPicking joint bandwidth of 15.5\n\n\nWarning: Removed 468 rows containing non-finite outside the scale range\n(`stat_density_ridges()`).\n\n\n\n\n\n\n\n\n\n\nchange the ordering of the years axis\ndata is being more bimodal over time\nLet‚Äôs look closer into these differences by country\n\n\n\nCode\nall_scores_long |&gt;\n  filter(year &gt; 2017) |&gt;\n  filter(!is.na(score)) |&gt;\n  ggplot(aes(x = score, y = fct_reorder2(country, year==\"2022\", score), color=as.factor(year))) +\n  geom_point(alpha=0.5) +\n  ggtitle(\"PISA Scores in 2018 vs. 2022\") +\n  ylab(\"\") +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n\nmake a note about the three colors that are appearing\nwe see that actually the countries whose scores differed greatly were higher performing countries; that‚Äôs wack\nthe change is getting worse\nwas the decrease from 2018 to 2022 significantly worse? Let‚Äôs look at the whole distribution\n\n\n\nCode\n# Plotting scores\nggplot(filter(all_reading_scores_long, country == \"OECD average\"), aes(year, score)) + \n  geom_point(data = filter(all_reading_scores_long, year &gt; 2010), aes(x=year, y=score), position='jitter') +\n  geom_point(size=4, color=\"red\") +\n  labs(x = \"Year\", y = \"OECD Average Reading Scores\") +\n  ggtitle(\"OECD Average Reading Scores from 2012-2022\")\n\n\nWarning: Removed 121 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nCode\nggplot(filter(all_math_scores_long, country == \"OECD average\"), aes(x=year, y=score)) + \n  geom_point(data = filter(all_math_scores_long, year &gt; 2010), aes(x=year, y=score), position='jitter') +\n  geom_point(size=4, color=\"red\") +\n  labs(x = \"Year\", y = \"OECD Average Math Scores\") +\n  ggtitle(\"OECD Average Math Scores from 2012-2022\")\n\n\nWarning: Removed 118 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nCode\nggplot(filter(all_science_scores_long, country == \"OECD average\"), aes(year, score)) + \n  geom_point(data = filter(all_science_scores_long, year &gt; 2010), aes(x=year, y=score), position='jitter') +\n  geom_point(size=4, color=\"red\") +\n  labs(x = \"Year\", y = \"OECD Average Science Scores\") +\n  ggtitle(\"OECD Average Science Scores from 2012-2022\")\n\n\nWarning: Removed 118 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nCode\n# Change the x axis to only show the years we wanna see\n\n\n\nHard to tell. Let‚Äôs try to predict 2022\n\n\n\nCode\n# Reading Predictions\nreading_scores_train &lt;- all_reading_scores_long |&gt;\n  filter(year &lt; 2020, country == \"OECD average\")\nreading_model &lt;- lm(score ~ year, data = reading_scores_train)\n\n# Predict for 2022\npredicted_value &lt;- predict(reading_model, newdata = data.frame(year = 2022))\nprint(predicted_value)\n\n\n    1 \n481.5 \n\n\nCode\n# Plot new model\nggplot(reading_scores_train, aes(year, score)) + \n  geom_point(data=filter(all_reading_scores_long, country == \"OECD average\"), aes(year, score)) +\n  geom_point(data=data.frame(year = 2022, score = predicted_value), color = \"blue\", size=3) +\n  geom_abline(intercept = coef(reading_model)[1], slope = coef(reading_model)[2], \n              color = \"blue\", linewidth = 1) +\n  labs(x = \"Year\", y = \"OECD Average Reading Scores\") +\n  ggtitle(\"Predicting 2022 OECD Average Reading Score\")\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nCode\n# Math Predictions\nmath_scores_train &lt;- all_math_scores_long |&gt;\n  filter(year &lt; 2020, country == \"OECD average\")\nmath_model &lt;- lm(score ~ year, data = math_scores_train)\n\n# Predict for 2022\npredicted_value &lt;- predict(math_model, newdata = data.frame(year = 2022))\nprint(predicted_value)\n\n\n       1 \n485.1667 \n\n\nCode\n# Plot new model\nggplot(math_scores_train, aes(year, score)) + \n  geom_point(data=filter(all_math_scores_long, country == \"OECD average\"), aes(year, score)) +\n  geom_point(data=data.frame(year = 2022, score = predicted_value), color = \"blue\", size=3) +\n  geom_abline(intercept = coef(math_model)[1], slope = coef(math_model)[2], \n              color = \"blue\", linewidth = 1) +\n  labs(x = \"Year\", y = \"OECD Average Mathematics Scores\") +\n  ggtitle(\"Predicting 2022 OECD Average Mathematics Score\")\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nCode\n# Science Predictions\nscience_scores_train &lt;- all_science_scores_long |&gt;\n  filter(year &lt; 2020, country == \"OECD average\")\nscience_model &lt;- lm(score ~ year, data = science_scores_train)\n\n# Predict for 2022\npredicted_value &lt;- predict(science_model, newdata = data.frame(year = 2022))\nprint(predicted_value)\n\n\n       1 \n480.3333 \n\n\nCode\n# Plot new model\nggplot(science_scores_train, aes(year, score)) + \n  geom_point(data=filter(all_science_scores_long, country == \"OECD average\"), aes(year, score)) +\n  geom_point(data=data.frame(year = 2022, score = predicted_value), color = \"blue\", size=3) +\n  geom_abline(intercept = coef(science_model)[1], slope = coef(science_model)[2], \n              color = \"blue\", linewidth = 1) +\n  labs(x = \"Year\", y = \"OECD Average Science Scores\") +\n  ggtitle(\"Predicting 2022 OECD Average Science Score\")\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nreading and math scores dropped significantly\nscience was ok somehow\nyes there were only three years so we cant trust this trend too much\nbut each point was being created by the average of millions of students across the world\nwe have a lack of time(years) for this data but we dont have a lack of data\n\n\n\n3.0.2 Other factors\n\nintro to this section is gonna be: we have now concluded that there is a sig dip from 2018-2022 but we can‚Äôt say it‚Äôs just bc of covid so lets look at some other factors ‚Äî&gt; see if there is a correlation between COVID and GDP, COVID and spending\npisa vs spending\n\ndiff countries spend diff\n\n\n\n\nCode\n #| fig-width: 8\n #| fig-height: 20\n\npisa_Spending2018 &lt;- inner_join(\n  read.csv(\"data/2018_GDP.csv\"),\n  read.csv(\"data/2018_Spending.csv\"),\n  by = \"Country\"\n) %&gt;%\n  select(Country, Score, Spending) %&gt;%\n  mutate(\n    Score = as.numeric(Score),\n    Spending = as.numeric(Spending)\n  )\n\npisa_points &lt;- pisa_Spending2018 %&gt;%\n  filter(Country != \"OECD average\")\n\noecd_avg_score &lt;- pisa_Spending2018 %&gt;% \n  filter(Country == \"OECD average\") %&gt;% \n  pull(Score)\n\nmean_s &lt;- pisa_points %&gt;% \n  summarize(mean_s = mean(Spending, na.rm = TRUE)) %&gt;% \n  pull(mean_s)\n\npisa_points &lt;- pisa_points %&gt;%\n  mutate(\n    Above_Both = Score &gt; oecd_avg_score & Spending &gt; mean_s\n  )\n\n\n# --- Improved Plot ---\nggplot(pisa_points, aes(x = Spending, y = Score)) +\n  \n  # Points\n  geom_point(aes(color = Above_Both), size = 3.8) +\n  \n  # Nice, readable text labels\n  geom_text_repel(\n    aes(label = Country),\n    size = 3.2,\n    box.padding = 0.5,\n    point.padding = 0.3,\n    min.segment.length = 0,\n    max.overlaps = Inf,\n    segment.alpha = 0.3\n  ) +\n  \n  # Reference lines\n  geom_hline(yintercept = oecd_avg_score, \n             color = \"red\", linetype = \"dashed\", size = 1) +\n  geom_vline(xintercept = mean_s, \n             color = \"blue\", linetype = \"dotted\", size = 1) +\n\n  # Custom colors\n  scale_color_manual(\n    values = c(\"FALSE\" = \"grey40\", \"TRUE\" = \"#1f78b4\"),\n    labels = c(\"Other countries\", \"Above both thresholds\"),\n    name = \"\"\n  ) +\n  scale_x_continuous(labels = scales::comma)+\n\n  # Give breathing room so text isn't cut off\n  coord_cartesian(\n    clip = \"off\",\n    xlim = c(min(pisa_points$Spending) * 0.95, max(pisa_points$Spending) * 1.05),\n    ylim = c(min(pisa_points$Score) * 0.97, max(pisa_points$Score) * 1.03)\n  ) +\n\n  labs(\n    title = \"PISA 2018 Reading Score vs Spending\",\n    subtitle = \"Countries above OECD average reading score AND above Spending are highlighted\",\n    x = \"Spending\",\n    y = \"PISA Reading Score\"\n  ) +\n\n  # Much cleaner theme\n  theme_minimal(base_size = 13) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 18),\n    plot.subtitle = element_text(size = 12),\n    legend.position = \"bottom\",\n\n    # Remove excessive gridlines\n    panel.grid.minor = element_blank(),\n    panel.grid.major.y = element_line(color = \"grey85\"),\n    panel.grid.major.x = element_line(color = \"grey90\"),\n\n    # Prevent clipping of labels\n    plot.margin = margin(20, 20, 20, 20)\n  )\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n\nCode\n #| fig-width: 8\n #| fig-height: 12\n\npisa_Spending2022 &lt;- inner_join(\n  read.csv(\"data/2022_Spending.csv\"),\n  read.csv(\"data/2022_PISA.csv\"),\n  by = \"Country\"\n) %&gt;%\n  select(Country, Reading.Mean, Spending) %&gt;%\n  mutate(\n    Reading.Mean = as.numeric(Reading.Mean),\n    Spending = as.numeric(Spending)\n  )\n\n\nWarning: There was 1 warning in `mutate()`.\n‚Ñπ In argument: `Reading.Mean = as.numeric(Reading.Mean)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\nCode\npisa_points &lt;- pisa_Spending2022 %&gt;%\n  filter(Country != \"OECD average\")\n\noecd_avg_score &lt;- pisa_Spending2022 %&gt;% \n  filter(Country == \"OECD average\") %&gt;% \n  pull(Reading.Mean)\n\nmean_sp &lt;- pisa_points %&gt;% \n  summarize(mean_sp = mean(Spending, na.rm = TRUE)) %&gt;% \n  pull(mean_sp)\n\npisa_points &lt;- pisa_points %&gt;%\n  mutate(\n    Above_Both = Reading.Mean &gt; oecd_avg_score & Spending &gt; mean_sp\n  )\n\n# --- Improved Plot ---\nggplot(pisa_points, aes(x = Spending, y = Reading.Mean)) +\n  \n  # Points\n  geom_point(aes(color = Above_Both), size = 3.8) +\n  \n  # Nice, readable text labels\n  geom_text_repel(\n    aes(label = Country),\n    size = 3.2,\n    box.padding = 0.5,\n    point.padding = 0.3,\n    min.segment.length = 0,\n    max.overlaps = Inf,\n    segment.alpha = 0.3\n  ) +\n  \n  # Reference lines\n  geom_hline(yintercept = oecd_avg_score, \n             color = \"red\", linetype = \"dashed\", size = 1) +\n  geom_vline(xintercept = mean_sp, \n             color = \"blue\", linetype = \"dotted\", size = 1) +\n\n  # Custom colors\n  scale_color_manual(\n    values = c(\"FALSE\" = \"grey40\", \"TRUE\" = \"#1f78b4\"),\n    labels = c(\"Other countries\", \"Above both thresholds\"),\n    name = \"\"\n  ) +\n\n  # Give breathing room so text isn't cut off\n  coord_cartesian(\n    clip = \"off\",\n    xlim = c(min(pisa_points$Spending) * 0.95, max(pisa_points$Spending) * 1.05),\n    ylim = c(min(pisa_points$Reading.Mean) * 0.97, max(pisa_points$Reading.Mean) * 1.03)\n  ) +\n\n  labs(\n    title = \"PISA 2022 Reading Score vs Spending\",\n    subtitle = \"Countries above OECD average reading score AND above mean Spending\",\n    x = \"Spending\",\n    y = \"PISA Reading Score\"\n  ) +\n\n  # Much cleaner theme\n  theme_minimal(base_size = 13) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 18),\n    plot.subtitle = element_text(size = 12),\n    legend.position = \"bottom\",\n\n    # Remove excessive gridlines\n    panel.grid.minor = element_blank(),\n    panel.grid.major.y = element_line(color = \"grey85\"),\n    panel.grid.major.x = element_line(color = \"grey90\"),\n\n    # Prevent clipping of labels\n    plot.margin = margin(20, 20, 20, 20)\n  )\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_text_repel()`).\n\n\n\n\n\n\n\n\n\n\ngraph: spendin 2018 - 2022\n\nwoah change or no change\n\nchange could be bc of gdp if a countru has more money they will spend more on ending\n\n\n\nGRAPH TO BE CREATED\n\nGDP vs spending\n\nthere is a corr\n\n\n\n\nCode\nGDP_precovid&lt;- read.csv('data/2018_GDP.csv')\nspending_precovid&lt;- read.csv('data/2018_Spending.csv')\n\nmerged_data &lt;- merge(GDP_precovid, spending_precovid, by = \"Country\")\n\n\n\n\nCode\n#2018\n\n# Define the specific countries you want to label\ntarget_countries &lt;- c(\"Qatar\", \"Macao (China)\", \"Singapore\", \"Austria\", \"Iceland\",'Finland')\n\nggplot(merged_data, aes(x = GDP, y = Spending)) +\n  geom_point(color = \"blue\", size = 2) +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"grey50\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkred\") +\n  \n  geom_text_repel(\n    # Filter data to only label the target countries\n    data = merged_data[merged_data$Country %in% target_countries, ], \n    aes(label = Country), \n    size = 3,                       \n    segment.color = 'grey50',       \n    segment.size = 0.2,             \n    box.padding = unit(0.5, \"lines\"), \n    point.padding = unit(0.5, \"lines\"),\n    force = 2\n  ) +\n  \n  # Set X-axis limits and format (NO scientific notation)\n  scale_x_continuous(\n    labels = label_number(big.mark = \",\"), # Format to full number with commas\n    limits = c(0, max(merged_data$GDP) * 1.05) # Incorporate the limit here\n  ) +\n  \n  # Set Y-axis limits and format (NO scientific notation)\n  scale_y_continuous(\n    labels = label_number(big.mark = \",\"), # Format to full number with commas\n    limits = c(0, max(merged_data$Spending) * 1.05) # Incorporate the limit here\n  ) +\n  \n  # Labels and Theme\n  labs(\n    title = \"GDP vs. Spending Correlation (2018) - Selected Countries Highlighted\",\n    x = \"GDP (in currency units from table)\",\n    y = \"Spending (in currency units from table)\",\n    caption = \"Linear trend line (dark red) shows relationship. Dashed line (grey) is y=x.\"\n  ) +\n  theme_minimal() \n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nCode\n# dashed is y = x\n\n\n\n\nCode\nGDP_postcovid&lt;- read.csv('data/2022_GDP.csv')\nspending_postcovid&lt;- read.csv('data/2022_Spending.csv')\n\nmerged_data2 &lt;- merge(GDP_postcovid, spending_postcovid, by = \"Country\")\nnames(merged_data2)[2] &lt;- \"GDP\"\n\n\n\n\nCode\n# Define the specific countries you want to label\ntarget_countries &lt;- c(\"Qatar\", \"Macao (China)\", \"Luxembourg\", \"Singapore\", \"Austria\", \"Iceland\", 'Finland')\n\nggplot(merged_data2, aes(x = GDP, y = Spending)) +\n  geom_point(color = \"blue\", size = 2) +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"grey50\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkred\") +\n  \n  geom_text_repel(\n    # Filter data to only label the target countries\n    data = merged_data2[merged_data2$Country %in% target_countries, ], \n    aes(label = Country), \n    size = 3,                       \n    segment.color = 'grey50',       \n    segment.size = 0.2,             \n    box.padding = unit(0.5, \"lines\"), \n    point.padding = unit(0.5, \"lines\"),\n    force = 2\n  ) +\n  \n  # Set X-axis limits and format (NO scientific notation)\n  scale_x_continuous(\n    labels = label_number(big.mark = \",\"), # Format to full number with commas\n    limits = c(0, max(merged_data2$GDP) * 1.05) # Incorporate the limit here\n  ) +\n  \n  # Set Y-axis limits and format (NO scientific notation)\n  scale_y_continuous(\n    labels = label_number(big.mark = \",\"), # Format to full number with commas\n    limits = c(0, max(merged_data2$Spending) * 1.05) # Incorporate the limit here\n  ) +\n  \n  # Labels and Theme\n  labs(\n    title = \"GDP vs. Spending Correlation (2022) - Selected Countries Highlighted\",\n    x = \"GDP (in currency units from table)\",\n    y = \"Spending (in currency units from table)\",\n    caption = \"Linear trend line (dark red) shows relationship. Dashed line (grey) is y=x.\"\n  ) +\n  theme_minimal() \n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nCode\n# dashed is y = x\n\n\n\npisa vs gdp -bc gdp and spending are correlated we see the same type of corr so this prove that gdp and spending are correlated\nGRAPH TO BE CREATED\n\nwe end on how has GDP changed (graph: GDP 2018-2022) - get rid of insane colors - color with red and green‚Äì&gt; threshold of the expected slope\n\n\nCode\ngdp_2018 &lt;- read.csv('data/2018_GDP.csv') |&gt;\n  mutate(country = Country, score = Score, gdp = GDP, year=\"2018\") |&gt;\n  select(\"country\", \"score\", \"gdp\", \"year\")\ngdp_2022 &lt;- read.csv('data/2022_GDP.csv') |&gt;\n  left_join(filter(all_reading_scores_long, year == 2022), by=c(\"Country\" = \"country\")) |&gt;\n  mutate(country = Country, gdp = GDP, year=\"2022\") |&gt;\n  select(\"country\", \"score\", \"gdp\", \"year\")\n\ngdp &lt;- bind_rows(gdp_2018, gdp_2022) \n# |&gt;\n  #pivot_wider(names_from = year, values_from = gdp, names_prefix = \"gdp_\", values_fn = first) |&gt;\n  #mutate(change = gdp_2022 - gdp_2018)\n\nggplot(gdp, aes(x = as.factor(year), y = gdp, group = country)) +\n  geom_line(aes(color = country), linewidth = 1) +\n  geom_point(size = 3) +\n  labs(title = \"GDP Trend: 2018 to 2022\",\n       x = \"Year\", y = \"GDP\") +\n  theme(legend.position = \"none\") \n\n\n\n\n\n\n\n\n\n\nhas not increased as much as it did previously\nGDP will typically increase but the increase that we see here is not as high as the increase that we would typically want to see - largest reason for that is covid\nthough we can‚Äôt say that COVID is the only reason why the education system has changed, a lot of the other factors that affect education outcomes were effected by covid\n\n\n\n3.0.3 CASE STUDY: FINLAND\nFinland‚Äôs transition to distance learning went well, but the effect of switching meant that students no longer had equal access to the resources provided at school and their resources were limited to their homes. Meaning, any difference or inequity of educational support in their home life directly affected their educational performance/outcomes. This can be seen in their cynicism and burnout or whatever rates increasing\n\n\nCode\ndata_cynicism &lt;- read.csv(\"data/cynicism_finland.csv\")\ndata_cynicism &lt;- data_cynicism %&gt;%\n  rename(\n    High_school = colnames(data_cynicism)[4],\n  )\n\n# Convert data to long format for easier plotting\ndata_cynicism_long &lt;- data_cynicism %&gt;%\n  pivot_longer(\n    # Select the three school columns for pivoting\n    cols = c(High_school),\n    names_to = \"School_Type\",\n    values_to = \"Percentage\"\n  )\n\n\ncolor_map &lt;- c(\n  \"High_school\" = \"#6495ED\"  \n)\n\nlabel_map &lt;- c(\n  \"Comprehensive\" = \"Comprehensive school grades 8 and 9\",\n  \"High_school\" = \"High school grades 10 and 11\",\n  \"Vocational\" = \"Vocational school\"\n)\n\n# Create the plot\ncynicism_plot &lt;- ggplot(data_cynicism_long, aes(x = Year, y = Percentage, color = School_Type)) +\n  # Add the lines\n  geom_line(linewidth = 1) +\n  # Add the points (circles)\n  geom_point(size = 3) +\n  \n  # Set the custom colors and labels for the legend\n  scale_color_manual(\n    values = color_map, \n    labels = label_map,\n    name = NULL # Remove legend title\n  ) +\n  \n  # Customize the X-axis (Years)\n  scale_x_continuous(\n    breaks = data_cynicism$Year,\n    # Use the custom labels, noting 2013 and 2017 are single years in this set\n    labels = c(\"2007\", \"2009\", \"2011\", \"2013\", \"2017\", \"2019\", \"2021\"),\n    expand = expansion(add = c(0.5, 0.5))\n  ) +\n  \n  # Customize the Y-axis (Percentage) - Adjusted for higher values\n  scale_y_continuous(\n    limits = c(0, 40), # Set the y-axis range to accommodate up to 35.5\n    breaks = seq(0, 40, by = 5) # Set breaks every 5 units\n  ) +\n  \n  # Add labels\n  labs(\n    x = \"Year\",\n    y = \"Percentage of students reporting cynicism\"\n  ) +\n  \n  # Apply the clean theme\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    axis.title = element_text(size = 12, face = \"bold\"),\n    plot.background = element_rect(fill = \"white\", color = NA),\n    panel.background = element_rect(fill = \"white\", color = NA),\n    panel.grid.major = element_line(color = \"grey80\"),\n    panel.grid.minor = element_blank()\n  )\n# Display the plot\nprint(cynicism_plot)\n\n\n\n\n\n\n\n\n\nCode\n# 2020 vertical line to signify the start of pandemic \n# some kinda predictive thing to show that predicted value for 2021 is lower than actual to show hella increase in slope\n\n\n\n\nCode\ndata &lt;- read.csv(\"data/school_burnout_finland.csv\")\ndata_long &lt;- data %&gt;%\n  rename(\n    High_school = colnames(data)[4]\n  )\n\n\n\n\nCode\n# Ensure Year is numeric\ndata_long$Year &lt;- as.numeric(data_long$Year)\n\n# --- Regression and Prediction Setup ---\n# 2. Prepare the training data (up to 2019)\ndata_train &lt;- subset(data_long, Year &lt;= 2019)\n\n# 3. Fit the Linear Regression Model\nburnout_model &lt;- lm(High_school ~ Year, data = data_train)\n\n# 4. Predict the High_school value for 2021\nprediction_year &lt;- data.frame(Year = 2021)\npredicted_value &lt;- predict(burnout_model, newdata = prediction_year)\n\n# 5. Create data frames for plotting the actual and predicted points\npredicted_point &lt;- data.frame(\n  Year = 2021, \n  High_school = predicted_value,\n  Type = \"Predicted\"\n)\n\n# Create a data frame for all actual points, distinguishing the 2021 point\nactual_points &lt;- data_long\nactual_points$Type &lt;- \"Actual (2009-2019)\"\nactual_points[actual_points$Year == 2021, \"Type\"] &lt;- \"Actual (2021)\"\n\n# --- Combined Plot Generation ---\n\nggplot(data = actual_points, aes(x = Year, y = High_school)) +\n  \n  # A. Add the vertical shaded section (starting from 2020)\n  annotate(\n    geom = \"rect\",\n    xmin = 2020, \n    xmax = 2022, # Extends past 2021 to cover the right side of the plot\n    ymin = -Inf, \n    ymax = Inf,\n    fill = \"grey\", \n    alpha = 0.3\n  ) +\n  \n  # B. Plot the regression line (fitted on 2009-2019 data)\n  geom_smooth(\n    data = data_train, # Base the line on the training data\n    method = \"lm\", \n    se = FALSE, # Do not display standard error\n    color = \"darkgreen\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  \n  # C. Plot all actual data points\n  geom_point(aes(color = Type), size = 3) + \n  \n  # D. Highlight the predicted 2021 point\n  geom_point(\n    data = predicted_point, \n    aes(color = Type), \n    size = 4, \n    shape = 17 # Triangle shape\n  ) +\n  \n  # E. Connect the last actual point (2019) to the predicted 2021 point\n  geom_segment(\n    aes(\n      x = 2019, \n      y = actual_points[actual_points$Year == 2019, \"High_school\"], \n      xend = 2021, \n      yend = predicted_point[predicted_point$Year == 2021, \"High_school\"]\n    ),\n    linetype = \"dotted\",\n    color = \"darkgreen\",\n    linewidth = 1\n  ) +\n  \n  # üëá This forces the y-axis to include 0\n  expand_limits(y = 0) + \n  \n  # Add labels and theme...\n  labs(\n    title = \"Student Burnout (Persistent Sadness) Trends: Finland\",\n    subtitle = paste0(\n      \"Linear Prediction for 2021: \", round(predicted_value, 2), \n      \"% (Actual: \", actual_points[actual_points$Year == 2021, \"High_school\"], \"%)\"\n    ),\n    y = \"Percent of Students (%)\",\n    x = \"Year\"\n  ) +\n  theme_minimal() +\n  \n  # F. Customize colors and legend\n  scale_color_manual(\n    name = \"Data Point\",\n    values = c(\n      \"Actual (2009-2019)\" = \"black\", \n      \"Actual (2021)\" = \"red\", \n      \"Predicted\" = \"blue\"\n    )\n  ) +\n  \n  # Move the legend to a convenient location\n  theme(legend.position = \"bottom\")\n\n\nWarning: Use of `actual_points$Year` is discouraged.\n‚Ñπ Use `Year` instead.\n\n\nWarning in geom_segment(aes(x = 2019, y = actual_points[actual_points$Year == : All aesthetics have length 1, but the data has 8 rows.\n‚Ñπ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nCode\n# 2020 vertical line to signify the start of pandemic \n# some kinda predictive thing to show that predicted value for 2021 is lower than actual to show hella increase in slope\n\n\n\ngraph shows spike from 2019-2021\n\nThe transition to distance learning during the pandemic led to decreased engagement among students, teachers, and principals. This shift significantly increased stress and burnout for educators, with principals feeling the effects of their teachers‚Äô struggles. Teachers found it difficult to compensate for the inconsistent support students received back home. As seen in this teacher burnout graph: GRAPH OF TEACHER BURNOUT TO BE CREATED\nConclusion: The switch to distance learning was well-organized, but it ultimately made fairness in education worse and damaged the conditions needed for students to learn well and feel supported.\n\n\n3.0.4 CASE STUDY: USA\n\nfind a source to talk about whether the transition from diff modalities is trash and just generally how that transition went\n\n\n\nCode\n#### school modality \n\n#https://healthdata.gov/browse?q=school+learning+modalities&sortBy=relevance&pageSize=20\n\ndf &lt;- read.csv(\"data/school_modality.csv\") |&gt;\n  mutate(\n    Learning_Modality = as.factor(Learning_Modality),\n    Year = as.factor(Year)\n  )\n\ncounts &lt;- df |&gt;\n  group_by(Year, Learning_Modality) |&gt;\n  summarize(Freq = sum(Count), .groups = \"drop\")\n\ntbl &lt;- xtabs(Freq ~ Year + Learning_Modality, data = counts)\n\ncolors_theme &lt;- c(\"#FFB6B9\", \"#FAE3D9\", \"#61C0BF\")\n\nmosaic(\n  tbl,\n  direction = c(\"v\", \"h\"),\n  highlighting = \"Learning_Modality\",\n  highlighting_fill = colors_theme,\n  main = \"Learning Modality by Year\")\n\n\n\n\n\n\n\n\n\n\nfrom 2020 to 2022, the USA changed learning modality due to pandemic\nby the end of 2022, schools were back to hybrid\n‚ÄúK-12 public and independent charter school districts for the 2021-2022 school year and the Fall 2022 semester, from August 2021 ‚Äì December 2022‚Äù\n\n\n\nCode\n# HIGH SCHOOL STUDENTS\nusaburnout &lt;- read.csv(\"data/USA_burnout.csv\")\n# Ensure Year is numeric\nusaburnout$Year &lt;- as.numeric(usaburnout$Year)\n\n# --- Regression and Prediction Setup ---\n\n# 2. Prepare the training data (up to 2019)\nusaburnout_train &lt;- subset(usaburnout, Year &lt;= 2019)\n\n# 3. Fit the Linear Regression Model (using data up to 2019)\nburnout_model &lt;- lm(High_School ~ Year, data = usaburnout_train)\n\n# 4. Predict the High_School value for 2021\nprediction_year &lt;- data.frame(Year = 2021)\npredicted_value &lt;- predict(burnout_model, newdata = prediction_year)\n\n# 5. Create data frames for plotting the actual and predicted points\npredicted_point &lt;- data.frame(\n  Year = 2021, \n  High_School = predicted_value,\n  Type = \"Predicted\"\n)\n\n# Create a data frame for all actual points, distinguishing the 2021 point\nactual_points &lt;- usaburnout\nactual_points$Type &lt;- \"Actual (2007-2019)\"\nactual_points[actual_points$Year == 2021, \"Type\"] &lt;- \"Actual (2021)\"\n\n# --- Combined Plot Generation ---\n\nggplot(data = actual_points, aes(x = Year, y = High_School)) +\n  \n  # A. Add the vertical shaded section (starting from 2020)\n  annotate(\n    geom = \"rect\",\n    xmin = 2020, \n    xmax = 2022, # Extends past 2021 to cover the right side of the plot\n    ymin = -Inf, \n    ymax = Inf,\n    fill = \"grey\", \n    alpha = 0.3\n  ) +\n  \n  # B. Plot the regression line (fitted on 2007-2019 data)\n  geom_smooth(\n    data = usaburnout_train, # Base the line on the training data\n    method = \"lm\", \n    se = FALSE, # Do not display standard error\n    color = \"darkgreen\", \n    linetype = \"dashed\", \n    linewidth = 1\n  ) +\n  \n  # C. Plot all actual data points\n  geom_point(aes(color = Type), size = 3) + \n  \n  # D. Highlight the predicted 2021 point\n  geom_point(\n    data = predicted_point, \n    aes(color = Type), \n    size = 4, \n    shape = 17 # Triangle shape\n  ) +\n  \n  # E. Connect the last actual point (2019) to the predicted 2021 point\n  geom_segment(\n    aes(\n      x = 2019, \n      y = actual_points[actual_points$Year == 2019, \"High_School\"], \n      xend = 2021, \n      yend = predicted_point[predicted_point$Year == 2021, \"High_School\"]\n    ),\n    linetype = \"dotted\",\n    color = \"darkgreen\",\n    linewidth = 1\n  ) +\n  \n  expand_limits(y = 0) + \n  \n  labs(\n    title = \"Student Burnout (Persistent Sadness) Trends: USA\",\n    subtitle = paste0(\n      \"Linear Prediction for 2021: \", round(predicted_value, 2), \n      \"% (Actual: \", actual_points[actual_points$Year == 2021, \"High_School\"], \"%)\"\n    ),\n    y = \"Percent of Students (%)\",\n    x = \"Year\"\n  ) +\n  theme_minimal() +\n  \n  # F. Customize colors and legend\n  scale_color_manual(\n    name = \"Data Point\",\n    values = c(\n      \"Actual (2007-2019)\" = \"black\", \n      \"Actual (2021)\" = \"red\", \n      \"Predicted\" = \"blue\"\n    )\n  ) +\n  \n  # Move the legend to a convenient location\n  theme(legend.position = \"bottom\")\n\n\nWarning: Use of `actual_points$Year` is discouraged.\n‚Ñπ Use `Year` instead.\n\n\nWarning in geom_segment(aes(x = 2019, y = actual_points[actual_points$Year == : All aesthetics have length 1, but the data has 8 rows.\n‚Ñπ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nCode\n# 2020 vertical line to signify the start of pandemic \n# some kinda predictive thing to show that predicted value for 2021 is lower than actual to show hella increase in slope\n\n\n\ncheck the steady increase from 2019 to 2021 (COVID TIME)\ncould be because of the stress of pandemic and changes in school modality (refer to mosaic)\n\n\n\n3.0.5 Chloropleth, we are not sure if we are adding/using\n\n\nCode\npisa_gdp2018 = inner_join(read.csv(\"data/2018_GDP.csv\"), read.csv(\"data/2018_PISA.csv\"), by = \"Country\") %&gt;%\n  select(Country, Score, GDP)\n\nname_fix &lt;- c(\n  \"United States\" = \"United States of America\",\n  \"South Korea\" = \"Korea, Republic of\",\n  \"North Korea\" = \"Korea, Democratic People's Republic of\",\n  \"Iran\" = \"Iran, Islamic Republic of\",\n  \"Vietnam\" = \"Viet Nam\",\n  \"Egypt\" = \"Egypt, Arab Republic of\",\n  \"Czech Republic\" = \"Czechia\",\n  \"Syria\" = \"Syrian Arab Republic\",\n  \"Bolivia\" = \"Bolivia (Plurinational State of)\",\n  \"Brunei Darussalam\" = \"Brunei\",\n  \"Slovak Republic\" = \"Slovakia\",\n  \"Korea\" = \"South Korea\",\n  \"Baku (Azerbaijan)\" = \"Azerbaijan\",\n  \"Moldova\" = \"Moldova\",       \n  \"Kosovo\" = \"Kosovo\")\n\npisa_gdp2018$Country &lt;- recode(pisa_gdp2018$Country, !!!name_fix)\n\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\nworld_data &lt;- world %&gt;%\n  left_join(pisa_gdp2018, by = c(\"name\" = \"Country\"))\n\nmap_gdp &lt;- ggplot(world_data) +\n  geom_sf(aes(fill = GDP), color = \"white\", size = 0.1) +\n  scale_fill_viridis_c(option = \"plasma\", na.value = \"gray90\") +\n  labs(\n    title = \"GDP by Country\",\n    fill = \"GDP\"\n  ) +\n  theme_minimal()\n\nmap_score &lt;- ggplot(world_data) +\n  geom_sf(aes(fill = Score), color = \"white\", size = 0.1) +\n  scale_fill_viridis_c(option = \"plasma\", na.value = \"gray90\") +\n  labs(\n    title = \"PISA Score by Country\",\n    fill = \"Score\"\n  ) +\n  theme_minimal()\nmap_gdp\n\n\n\n\n\n\n\n\n\nCode\nmap_score\n\n\n\n\n\n\n\n\n\n\n\nCode\npisa_gdp2022 = inner_join(read.csv(\"data/2022_GDP.csv\"), read.csv(\"data/2022_PISA.csv\"), by = \"Country\") %&gt;%\n  select(Country, Reading.Mean, GDP)\n\n\n\nname_fix &lt;- c(\n  \"United States\" = \"United States of America\",\n  \"South Korea\" = \"Korea, Republic of\",\n  \"North Korea\" = \"Korea, Democratic People's Republic of\",\n  \"Iran\" = \"Iran, Islamic Republic of\",\n  \"Vietnam\" = \"Viet Nam\",\n  \"Egypt\" = \"Egypt, Arab Republic of\",\n  \"Czech Republic\" = \"Czechia\",\n  \"Syria\" = \"Syrian Arab Republic\",\n  \"Bolivia\" = \"Bolivia (Plurinational State of)\",\n  \"Brunei Darussalam\" = \"Brunei\",\n  \"Slovak Republic\" = \"Slovakia\",\n  \"Korea\" = \"South Korea\",\n  \"Baku (Azerbaijan)\" = \"Azerbaijan\",\n  \"Moldova\" = \"Moldova\",       \n  \"Kosovo\" = \"Kosovo\")\n\npisa_gdp2022$Country &lt;- recode(pisa_gdp2022$Country, !!!name_fix)\n\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\nworld_data &lt;- world %&gt;%\n  left_join(pisa_gdp2022, by = c(\"name\" = \"Country\"))\n\nmap_gdp &lt;- ggplot(world_data) +\n  geom_sf(aes(fill = GDP), color = \"white\", size = 0.1) +\n  scale_fill_viridis_c(option = \"plasma\", na.value = \"gray90\") +\n  labs(\n    title = \"GDP by Country\",\n    fill = \"GDP\"\n  ) +\n  theme_minimal()\n\nmap_score &lt;- ggplot(world_data) +\n  geom_sf(aes(fill = Reading.Mean), color = \"white\", size = 0.1) +\n  scale_fill_viridis_c(option = \"plasma\", na.value = \"gray90\") +\n  labs(\n    title = \"PISA Score by Country\",\n    fill = \"Score\"\n  ) +\n  theme_minimal()\nmap_gdp\n\n\n\n\n\n\n\n\n\nCode\n#map_score",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Results</span>"
    ]
  }
]